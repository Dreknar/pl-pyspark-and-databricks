# Databricks notebook source
# MAGIC %md
# MAGIC # Delta Table
# MAGIC
# MAGIC MoÅ¼emy nazwaÄ‡, Å¼e delta to "rozbudowany" parquet. Dostarcza on dodatkowe funkcjonalnoÅ›ci jak: walidacjÄ™ schematu, transakcyjnoÅ›Ä‡ oraz nowe polecenie z zakresu DML: ```MERGE INTO```. Delta jest automatycznie zainstalowana i wspierana przez klastry Databricks (nie musimy nic dodatkowo instalowaÄ‡).
# MAGIC
# MAGIC Oficjalna strona projektu dostÄ™pna pod tym [linkiem](https://delta.io/).

# COMMAND ----------

# DBTITLE 1,Tworzenie bazy danych
# MAGIC %sql
# MAGIC CREATE DATABASE IF NOT EXISTS demo_db;

# COMMAND ----------

# MAGIC %md
# MAGIC ## Tworzenie tabeli
# MAGIC
# MAGIC W przypadku Databricks domyÅ›lnie bÄ™dzie tworzona tabela w formacie delta. Mamy dostÄ™pnÄ… klasycznÄ… skÅ‚adnie SQL. Delta wprowadza rÃ³wnieÅ¼ atrybuty jal constrainty czy PRIMARY/FOREIGN KEY. Jest rÃ³wnieÅ¼ moÅ¼liwoÅ›Ä‡ tworzenia tabeli na podstawie danych zapisanych na dysku.
# MAGIC
# MAGIC - [Tworzenie tabeli - skÅ‚adnia (oficjalna dokumentacja)](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-syntax-ddl-create-table-using)
# MAGIC
# MAGIC > âœ… NiezaleÅ¼nie od wybranej opcji dobrÄ… praktykÄ… jest podawanie lokalizacji danych (```LOCATION```) oraz partycjonowanie danych (```PARTITIONED BY```).
# MAGIC
# MAGIC > âš ï¸ KolejnoÅ›Ä‡ podawania kolumn, ktÃ³rÄ… biorÄ… udziaÅ‚ w tworzeniu partycji ma znaczenie! Dodatkowo wartoÅ›ci w kolumnach nie mogÄ… koÅ„czyÄ‡ siÄ™ znakiem specjalnym np. kropkÄ….
# MAGIC
# MAGIC > âš ï¸ Nie wybieramy nigdy do partycji kolumny, ktÃ³re majÄ… PRIMARY KEY lub wartoÅ›ci unikatowe. Powoduje to duÅ¼y rozkÅ‚ad danych, co ostatnie wydÅ‚uÅ¼a czas odczytywania danych.
# MAGIC
# MAGIC - [Typy danych - oficjalna dokumentacja](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-datatypes)
# MAGIC - Funkcje: [AgregujÄ…ce](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-functions-builtin#aggregate-functions) [Analityczne](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-functions-builtin#analytic-window-functions) [Listy](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-functions-builtin#array-functions) [Mapy/SÅ‚ownika](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-functions-builtin#map-functions) [Rankingowe](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-functions-builtin#ranking-window-functions)
# MAGIC - [Funkcje dla delta SQL - oficjalna dokumentacja](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-functions-builtin)
# MAGIC

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad: skÅ‚adnia SQL
# MAGIC %sql
# MAGIC CREATE TABLE IF NOT EXISTS demo_db.tbl1 (
# MAGIC   -- nazwa_kolumny typ_danych|funkcja
# MAGIC   col1 STRING,
# MAGIC   col2 DOUBLE,
# MAGIC   col3 DATE,
# MAGIC   col4 TIMESTAMP,
# MAGIC   col5 DOUBLE GENERATED ALWAYS AS (col2 * 1.23),
# MAGIC   col6 INT NOT NULL
# MAGIC )
# MAGIC PARTITIONED BY (col3)
# MAGIC LOCATION '/FileStore/demo/db/tbl1.delta'

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad: DF + SQL
DATA_DIR = f'file:/Workspace/Repos/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/pl-pyspark-and-databricks/data'
df = spark.read.parquet(f'{DATA_DIR}/parquet/netflix_titles.parquet')

df.write.partitionBy("release_year").format("delta").mode("overwrite").save("/FileStore/demo/db/netflix-tbl.delta")

dbutils.fs.ls("/FileStore/demo/db/netflix-tbl.delta")

# COMMAND ----------

# MAGIC %sql
# MAGIC CREATE TABLE IF NOT EXISTS demo_db.netflix_demo USING DELTA LOCATION '/FileStore/demo/db/netflix-tbl.delta';

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT * FROM demo_db.netflix_demo LIMIT 10;

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad - sprawdzenie struktury
# MAGIC %sql
# MAGIC DESCRIBE FORMATTED demo_db.netflix_demo; 

# COMMAND ----------

# MAGIC %md
# MAGIC ## Modyfikacja tabeli
# MAGIC
# MAGIC - [ALTER TABLE - oficjalna dokumentacja](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-syntax-ddl-alter-table)
# MAGIC
# MAGIC Nie ma moÅ¼liwoÅ›ci usuniÄ™cia kolumny, jeÅ¼eli:
# MAGIC - Bierze udziaÅ‚ w tworzeniu partycji
# MAGIC - Jest na niej naÅ‚oÅ¼ony PRIMARY KEY
# MAGIC - Inna kolumna jest od niej zaleÅ¼na (np. uÅ¼ywa w ```CONSTRAINT``` lub ```GENERATED AS```)

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad: dodanie kolumny
# MAGIC %sql
# MAGIC ALTER TABLE demo_db.tbl1 ADD COLUMN col_x INT;

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad: constraint check
# MAGIC %sql
# MAGIC ALTER TABLE demo_db.tbl1 ADD CONSTRAINT check_col3_range CHECK (col3 >= 100 AND col3 <= 1000);

# COMMAND ----------

# MAGIC %md
# MAGIC ## UsuniÄ™cie tabeli
# MAGIC
# MAGIC PamiÄ™tamy rÃ³wnieÅ¼ o usuniÄ™ciu danych (pliki nie sÄ… usuwanie przy poleceniu ```DROP```)

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad
# MAGIC %sql
# MAGIC DROP TABLE IF EXISTS demo_db.tbl1;

# COMMAND ----------

dbutils.fs.rm('/FileStore/demo/db/tbl1.delta', True)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Podstawowe polecenia DML
# MAGIC
# MAGIC > âœ… PoniÅ¼ej polecenia oparte o SQL, natomiast moÅ¼na rÃ³wnieÅ¼ modyfikowaÄ‡ dane poprzez wykonywanie zapisu danych na DataFrame.
# MAGIC
# MAGIC > ðŸ”º Dane usuwamy tylko za pomocÄ… SQL. Z powodu tworzenia logÃ³w usuniÄ™cie danych poprzez usuniÄ™cie plikÃ³w powoduje uszkodzenie tabeli!!!

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad: INSERT
# MAGIC %sql
# MAGIC INSERT INTO demo_db.tbl1(col1,col2,col3,col4,col6) VALUES ('A', 2.25, '2024-01-01', '20204-01-01 12:00:30', 120);

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad: UPDATE
# MAGIC %sql
# MAGIC UPDATE demo_db.tbl1 SET col6 = 120 WHERE col1 = 'A';

# COMMAND ----------

# DBTITLE 1,PrzykÅ‚ad: DELETE
# MAGIC %sql
# MAGIC DELETE FROM demo_db.tbl1;

# COMMAND ----------

# MAGIC %md
# MAGIC ## Polecenie MERGE INTO
# MAGIC
# MAGIC Polecenie MERGE INTO to prawdziwy kombajn dla delta table. Pozwala on aktualizowaÄ‡ tabelÄ™ na podstawie innego DataFrame. Na podstawie warunku zÅ‚Ä…czenia moÅ¼emy zdecydowaÄ‡ co naleÅ¼y wykonaÄ‡, jeÅ¼eli dane zostaÅ‚y/nie zostaÅ‚y znalezione w danym zbiorze. ```SOURCE``` oznacza aktualizowanÄ… tabelÄ™, natomiast ```TARGET``` DataFrame na podstawie ktÃ³rego wykonujemy aktualizacjÄ™.
# MAGIC
# MAGIC > [Oficjalna dokumentacja MERGE INTO](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/delta-merge-into)
# MAGIC
# MAGIC OgÃ³lna skÅ‚adnia
# MAGIC ```delta
# MAGIC MERGE INTO src
# MAGIC USING trg ON trg.col = src.col -- Warunek zÅ‚Ä…czenia. MoÅ¼na rozbudowaÄ‡ o inne funkcje
# MAGIC -- Po MATCHED moÅ¼emy dodaÄ‡ BY SOURCE|TARGET, kiedy interesuje nas dopasowanie/brak dopasowanie po wybranej stronie. MoÅ¼na rozbudowaÄ‡ o kolejne funkcje.
# MAGIC WHEN NOT MATCHED THEN -- Kiedy dane nie zostaÅ‚y dopasowane
# MAGIC     -- polecenie DML np. INSERT *, UPDATE SET src.col = trg.col * 100
# MAGIC WHEN MATCHED THEN -- Kiedy dane zostaÅ‚y dopasowane
# MAGIC     --- polecenie DML np. DELETE *
# MAGIC ```
# MAGIC
# MAGIC > âœ… Rekomendowane jest uÅ¼ywanie ```%sql``` w przypadku MERGE INTO niÅ¼ poleceÅ„ Python podczas pracy w Databricks.
# MAGIC
# MAGIC > âš ï¸ MoÅ¼emy umieÅ›ciÄ‡ po jednym ```WHEN MATCHED``` i ```WHEN NOT MATCHED```
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC PrzykÅ‚ad poniÅ¼sza pokazuje:
# MAGIC 1. Przygotowanie danych. ```SOURCE``` zawiera tylko dane z 2020-2021, a ```TARGET``` 2019-2020.
# MAGIC 2. Dla danych z:
# MAGIC     - 2019 roku -> dodaj je. ```WHEN NOT MATCHED```
# MAGIC     - 2020 roku -> zaktualizuj poprzez wykonanie na tytule funkcji UPPER ```WHEN MATCHED```

# COMMAND ----------

# DBTITLE 1,Przygotowanie danych
# MAGIC %sql
# MAGIC DELETE FROM demo_db.netflix_demo WHERE release_year NOT IN (2021,2020);

# COMMAND ----------

import pyspark.sql.functions as F
df_update = spark.read.parquet(f'{DATA_DIR}/parquet/netflix_titles.parquet').filter( (F.col("release_year").isin([2019, 2020])) )
df_update.createOrReplaceTempView("df_update")

# COMMAND ----------

# MAGIC %sql
# MAGIC MERGE INTO demo_db.netflix_demo AS src
# MAGIC USING df_update AS trg ON trg.show_id = src.show_id
# MAGIC WHEN MATCHED THEN
# MAGIC   UPDATE
# MAGIC   SET src.title = UPPER(src.title)
# MAGIC WHEN NOT MATCHED BY TARGET THEN
# MAGIC   INSERT * 

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT * FROM demo_db.netflix_demo WHERE release_year = 2020 LIMIT 2;

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT * FROM demo_db.netflix_demo WHERE release_year = 2019 LIMIT 2;
